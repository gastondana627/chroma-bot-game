ğŸ“– Project README (Updated)

ğŸš€ Overview

This project is a Chroma Bot AI Chat Experience with:
	â€¢	FastAPI backend (AI responses via OpenAI).
	â€¢	Node/Express (server.js) serving static files for local testing & Vercel deployment.
	â€¢	Frontend animations (Chroma logo animation + fireworks).
	â€¢	Story arcs with potential â€œscamâ€ failure sequences (logo breaking).

Currently tested locally on MacOS + Python 3.12 + Node.js.

---

## Workflow

- Keep this repo **standalone** for now (UI/UX experiments).  
- Once the Chroma Bot sequences are stable â†’ merge into main game repo under a `/modules/chroma-bot/` directory.  
- This keeps development modular and avoids blocking the larger game flow.  

---

## Localhost â†’ Production Notes

- Localhost will be simple (static file server, e.g. `npm run dev` or `python3 -m http.server`).  
- Production on **Vercel** will auto-deploy this repo once connected.  
- When integrated into main repo â†’ Vercel can be configured with separate build outputs for `game/` and `chroma-bot/`.

---

## Next Steps

- Add the 5 **Chroma breaking images** under `/assets/images/`.  
- Add glitch/horror audio under `/assets/audio/`.  
- Scaffold a simple A-Frame scene in `src/index.html`.  
- Test UI cracking logic in isolation before merging with main game.


## Workflow structure
Data_Bleed_VSC/
â”‚â”€â”€ chroma-bot/          # Frontend (static files, served by Node.js or Vercel)
â”‚   â”œâ”€â”€ assets/          # Images, video, configs
â”‚   â”œâ”€â”€ script.js        # Main frontend logic (chat + fireworks + state logic)
â”‚   â”œâ”€â”€ chatbot.html     # Chatbot UI
â”‚   â””â”€â”€ server.js        # Node server for local static hosting
â”‚
â”‚â”€â”€ main.py              # FastAPI backend for AI responses
â”‚â”€â”€ .env                 # Environment variables (API keys)
â”‚â”€â”€ venv/                # Python virtual environment


ğŸ”‘ Environment Variables

Create a file named .env inside chroma-bot/ or project root:
OPENAI_API_KEY=sk-xxxxxx

ğŸ–¥ï¸ Local Development

1. Setup Python (FastAPI backend)
cd ~/Downloads/Data_Bleed_VSC
python3 -m venv venv
source venv/bin/activate

pip install -r requirements.txt

Run FastAPI:
uvicorn main:app --reload --port 3001

You should see:
âœ… OPENAI_API_KEY loaded successfully.
Uvicorn running on http://127.0.0.1:3001


2. Setup Node (Frontend static files)

cd ~/Downloads/Data_Bleed_VSC/chroma-bot
npm install
node server.js

You should see:
âœ… Server running at http://localhost:3001

3. Open in Browser

Go to:
ğŸ‘‰ http://localhost:3001/chatbot.html


âœ¨ Features

âœ… Already Working
	â€¢	Frontend chat box (script.js) with AI backend fallback.
	â€¢	Fireworks animation on click.
	â€¢	State transitions (normal â†’ tired â†’ broken).
	â€¢	FastAPI successfully connected to OpenAI API.
